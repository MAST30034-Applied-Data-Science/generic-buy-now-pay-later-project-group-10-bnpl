{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import lbl2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import date_format\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:51:46 WARN Utils: Your hostname, MacBook-Air-3.local resolves to a loopback address: 127.0.0.1; using 192.168.0.66 instead (on interface en0)\n",
      "22/10/04 21:51:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:51:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kasturi/opt/anaconda3/lib/python3.9/site-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:51:48 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:52:42 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_name</th><th>merchant_abn</th><th>categories</th><th>take_rate</th><th>revenue_levels</th><th>name</th><th>address</th><th>state</th><th>gender</th><th>trans_merchant_abn</th><th>dollar_value</th><th>order_id</th><th>order_datetime</th><th>user_id</th><th>consumer_id</th><th>postcodes</th><th>int_sa2</th><th>SA2_code</th><th>SA2_name</th><th>income_2018-2019</th><th>total_males</th><th>total_females</th><th>total_persons</th><th>state_code</th><th>state_name</th><th>population_2020</th><th>population_2021</th></tr>\n",
       "<tr><td>Egestas Nunc Asso...</td><td>11121775571</td><td>digital goods: bo...</td><td>6.58</td><td>a</td><td>Christopher Rodri...</td><td>30554 Evans Strea...</td><td>NSW</td><td>Male</td><td>11121775571</td><td>11.28829564583802</td><td>2bd2a61d-72e5-42d...</td><td>2021-08-20</td><td>3698</td><td>1175</td><td>2299</td><td>111031231</td><td>111031231</td><td>Shortland - Jesmond</td><td>242936885</td><td>6412</td><td>6179</td><td>12593</td><td>1</td><td>New South Wales</td><td>12598</td><td>12694</td></tr>\n",
       "<tr><td>Morbi Accumsan In...</td><td>19618998054</td><td>tent and aWning s...</td><td>1.52</td><td>c</td><td>Christopher Rodri...</td><td>30554 Evans Strea...</td><td>NSW</td><td>Male</td><td>19618998054</td><td>62.90176609196828</td><td>3582b1f8-4577-403...</td><td>2021-05-16</td><td>3698</td><td>1175</td><td>2299</td><td>111031231</td><td>111031231</td><td>Shortland - Jesmond</td><td>242936885</td><td>6412</td><td>6179</td><td>12593</td><td>1</td><td>New South Wales</td><td>12598</td><td>12694</td></tr>\n",
       "<tr><td>Eu Dolor Egestas PC</td><td>94472466107</td><td>cable, satellite,...</td><td>6.23</td><td>a</td><td>Christopher Rodri...</td><td>30554 Evans Strea...</td><td>NSW</td><td>Male</td><td>94472466107</td><td>172.15375126873164</td><td>cb05d49f-c2fa-453...</td><td>2021-07-22</td><td>3698</td><td>1175</td><td>2299</td><td>111031231</td><td>111031231</td><td>Shortland - Jesmond</td><td>242936885</td><td>6412</td><td>6179</td><td>12593</td><td>1</td><td>New South Wales</td><td>12598</td><td>12694</td></tr>\n",
       "<tr><td>Urna Justo Indust...</td><td>31472801314</td><td>music shops - mus...</td><td>6.56</td><td>a</td><td>Christopher Rodri...</td><td>30554 Evans Strea...</td><td>NSW</td><td>Male</td><td>31472801314</td><td>0.4894787650356477</td><td>aeec15c1-67e8-4cb...</td><td>2021-05-18</td><td>3698</td><td>1175</td><td>2299</td><td>111031231</td><td>111031231</td><td>Shortland - Jesmond</td><td>242936885</td><td>6412</td><td>6179</td><td>12593</td><td>1</td><td>New South Wales</td><td>12598</td><td>12694</td></tr>\n",
       "<tr><td>Eu Sem Pellentesq...</td><td>35424691626</td><td>computers, comput...</td><td>3.9</td><td>b</td><td>Christopher Rodri...</td><td>30554 Evans Strea...</td><td>NSW</td><td>Male</td><td>35424691626</td><td>7.360217018778133</td><td>9df473ba-102d-461...</td><td>2021-07-04</td><td>3698</td><td>1175</td><td>2299</td><td>111031231</td><td>111031231</td><td>Shortland - Jesmond</td><td>242936885</td><td>6412</td><td>6179</td><td>12593</td><td>1</td><td>New South Wales</td><td>12598</td><td>12694</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+------------+--------------------+---------+--------------+--------------------+--------------------+-----+------+------------------+------------------+--------------------+--------------+-------+-----------+---------+---------+---------+-------------------+----------------+-----------+-------------+-------------+----------+---------------+---------------+---------------+\n",
       "|       merchant_name|merchant_abn|          categories|take_rate|revenue_levels|                name|             address|state|gender|trans_merchant_abn|      dollar_value|            order_id|order_datetime|user_id|consumer_id|postcodes|  int_sa2| SA2_code|           SA2_name|income_2018-2019|total_males|total_females|total_persons|state_code|     state_name|population_2020|population_2021|\n",
       "+--------------------+------------+--------------------+---------+--------------+--------------------+--------------------+-----+------+------------------+------------------+--------------------+--------------+-------+-----------+---------+---------+---------+-------------------+----------------+-----------+-------------+-------------+----------+---------------+---------------+---------------+\n",
       "|Egestas Nunc Asso...| 11121775571|digital goods: bo...|     6.58|             a|Christopher Rodri...|30554 Evans Strea...|  NSW|  Male|       11121775571| 11.28829564583802|2bd2a61d-72e5-42d...|    2021-08-20|   3698|       1175|     2299|111031231|111031231|Shortland - Jesmond|       242936885|       6412|         6179|        12593|         1|New South Wales|          12598|          12694|\n",
       "|Morbi Accumsan In...| 19618998054|tent and aWning s...|     1.52|             c|Christopher Rodri...|30554 Evans Strea...|  NSW|  Male|       19618998054| 62.90176609196828|3582b1f8-4577-403...|    2021-05-16|   3698|       1175|     2299|111031231|111031231|Shortland - Jesmond|       242936885|       6412|         6179|        12593|         1|New South Wales|          12598|          12694|\n",
       "| Eu Dolor Egestas PC| 94472466107|cable, satellite,...|     6.23|             a|Christopher Rodri...|30554 Evans Strea...|  NSW|  Male|       94472466107|172.15375126873164|cb05d49f-c2fa-453...|    2021-07-22|   3698|       1175|     2299|111031231|111031231|Shortland - Jesmond|       242936885|       6412|         6179|        12593|         1|New South Wales|          12598|          12694|\n",
       "|Urna Justo Indust...| 31472801314|music shops - mus...|     6.56|             a|Christopher Rodri...|30554 Evans Strea...|  NSW|  Male|       31472801314|0.4894787650356477|aeec15c1-67e8-4cb...|    2021-05-18|   3698|       1175|     2299|111031231|111031231|Shortland - Jesmond|       242936885|       6412|         6179|        12593|         1|New South Wales|          12598|          12694|\n",
       "|Eu Sem Pellentesq...| 35424691626|computers, comput...|      3.9|             b|Christopher Rodri...|30554 Evans Strea...|  NSW|  Male|       35424691626| 7.360217018778133|9df473ba-102d-461...|    2021-07-04|   3698|       1175|     2299|111031231|111031231|Shortland - Jesmond|       242936885|       6412|         6179|        12593|         1|New South Wales|          12598|          12694|\n",
       "+--------------------+------------+--------------------+---------+--------------+--------------------+--------------------+-----+------+------------------+------------------+--------------------+--------------+-------+-----------+---------+---------+---------+-------------------+----------------+-----------+-------------+-------------+----------+---------------+---------------+---------------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data from ETL.py file\n",
    "%run '../scripts/ETL.py' '../scripts/paths.json'\n",
    "final_join3.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10540181"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_join3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_merchants = pd.read_csv(\"../data/curated/tagged_merchants.csv\")\n",
    "tagged_merchants = tagged_merchants.iloc[:,1:]\n",
    "tagged_merchants.drop(['tags', 'name', 'cleaned_tags', 'store_type'], axis=1, inplace=True)\n",
    "tagged_merchants.to_parquet(\"../data/curated/tagged_merchants.parquet\")\n",
    "tagged_merchants_sdf = spark.read.parquet(\"../data/curated/tagged_merchants.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_merchants_sdf = tagged_merchants_sdf.withColumnRenamed('merchant_abn',\n",
    "\n",
    "    'tagged_merchant_abn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|tagged_merchant_abn|            category|\n",
      "+-------------------+--------------------+\n",
      "|        10023283211|           Furniture|\n",
      "|        10142254217|         Electronics|\n",
      "|        10165489824|        Toys and DIY|\n",
      "|        10187291046|        Toys and DIY|\n",
      "|        10192359162|Books, Stationary...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_merchants_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_join3.createOrReplaceTempView(\"join\")\n",
    "tagged_merchants_sdf.createOrReplaceTempView(\"tagged\")\n",
    "\n",
    "joint = spark.sql(\"\"\" \n",
    "\n",
    "SELECT *\n",
    "FROM join\n",
    "INNER JOIN tagged\n",
    "ON join.merchant_abn = tagged.tagged_merchant_abn\n",
    "\"\"\")\n",
    "\n",
    "joint = joint.drop('tagged_merchant_abn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10109254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint.createOrReplaceTempView(\"group\")\n",
    "\n",
    "a = spark.sql(\"\"\" \n",
    "\n",
    "SELECT *, (take_rate - dollar_value) AS BNPL_earning\n",
    "FROM group\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the year, month, day from the timestamp\n",
    "\n",
    "a = a.withColumn(\"Year\", \n",
    "date_format('order_datetime', 'yyyy'))\n",
    "\n",
    "a  = a.withColumn(\"Month\", \n",
    "date_format('order_datetime', 'MMMM'))\n",
    "\n",
    "\n",
    "a = a.withColumn(\"Day\",\n",
    "date_format((\"order_datetime\"), \"E\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.drop('merchant_abn', 'categories','name', 'address', 'trans_merchant_abn', 'order_id','order_datetime','user_id','consumer_id','int_sa2',\n",
    "'SA2_name','state_code','state_name','population_2020', 'population_2021','BNPL_earning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 130:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+--------------+-----+------+------------+---------+--------+----------------+-----------+-------------+-------------+--------+----+-----+---+\n",
      "|merchant_name|take_rate|revenue_levels|state|gender|dollar_value|postcodes|SA2_code|income_2018-2019|total_males|total_females|total_persons|category|Year|Month|Day|\n",
      "+-------------+---------+--------------+-----+------+------------+---------+--------+----------------+-----------+-------------+-------------+--------+----+-----+---+\n",
      "|            0|        0|             0|    0|     0|           0|        0|       0|               0|          0|            0|            0|       0|   0|    0|  0|\n",
      "+-------------+---------+--------------+-----+------+------------+---------+--------+----------------+-----------+-------------+-------------+--------+----+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    " \n",
    "# Find Count of Null, None, NaN of All DataFrame Columns\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "a.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in a.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- take_rate: double (nullable = true)\n",
      " |-- revenue_levels: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- dollar_value: double (nullable = true)\n",
      " |-- postcodes: string (nullable = true)\n",
      " |-- SA2_code: long (nullable = true)\n",
      " |-- income_2018-2019: long (nullable = true)\n",
      " |-- total_males: long (nullable = true)\n",
      " |-- total_females: long (nullable = true)\n",
      " |-- total_persons: long (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              m_name|males|\n",
      "+--------------------+-----+\n",
      "|Pede Nonummy Corp...|    2|\n",
      "|Suspendisse Dui C...|    1|\n",
      "|Maecenas Industri...|    1|\n",
      "|Lorem Ipsum Sodal...|    1|\n",
      "|Ultricies Digniss...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 174:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|              f_name|females|\n",
      "+--------------------+-------+\n",
      "|Eget Company10902...|      2|\n",
      "|Taciti PC10902117...|      1|\n",
      "|Est Nunc Consulti...|      1|\n",
      "|Eget Metus In Cor...|      1|\n",
      "|Cras Eget Foundat...|      1|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a.createOrReplaceTempView(\"agg\")\n",
    "\n",
    "male = spark.sql(\"\"\" \n",
    "\n",
    "SELECT CONCAT(merchant_name, SA2_code, Year, Month, Day) AS m_name, COUNT(gender) as males\n",
    "FROM agg\n",
    "WHERE gender = 'Male'\n",
    "GROUP BY merchant_name, SA2_code, Year, Month, Day\n",
    "\"\"\")\n",
    "\n",
    "male.show(5)\n",
    "\n",
    "female = spark.sql(\"\"\" \n",
    "\n",
    "SELECT CONCAT(merchant_name, SA2_code, Year, Month, Day) AS f_name, COUNT(gender) as females\n",
    "FROM agg\n",
    "WHERE gender = 'Female'\n",
    "GROUP BY merchant_name, SA2_code, Year, Month, Day\n",
    "\"\"\")\n",
    "female.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 192:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------+-----+------+-----------------+---------+---------+----------------+-----------+-------------+-------------+--------------------+----+------+---+\n",
      "|       merchant_name|take_rate|revenue_levels|state|gender|     dollar_value|postcodes| SA2_code|income_2018-2019|total_males|total_females|total_persons|            category|Year| Month|Day|\n",
      "+--------------------+---------+--------------+-----+------+-----------------+---------+---------+----------------+-----------+-------------+-------------+--------------------+----+------+---+\n",
      "|Egestas Nunc Asso...|     6.58|             a|  NSW|  Male|11.28829564583802|     2299|111031231|       242936885|       6412|         6179|        12593|Books, Stationary...|2021|August|Fri|\n",
      "|Morbi Accumsan In...|     1.52|             c|  NSW|  Male|62.90176609196828|     2299|111031231|       242936885|       6412|         6179|        12593|Books, Stationary...|2021|   May|Sun|\n",
      "+--------------------+---------+--------------+-----+------+-----------------+---------+---------+----------------+-----------+-------------+-------------+--------------------+----+------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 209:===========================================>           (11 + 3) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------+----+------+---+--------------------+--------------------+\n",
      "|       merchant_name|no_of_transactions| SA2_code|Year| Month|Day|       BNPL_earnings|            join_col|\n",
      "+--------------------+------------------+---------+----+------+---+--------------------+--------------------+\n",
      "|    Euismod Enim LLC|                 1|210021234|2021|August|Fri| -19.056022223176804|Euismod Enim LLC2...|\n",
      "|Tempus Scelerisqu...|                 1|510021267|2021|August|Sun|  -9.093472011562348|Tempus Scelerisqu...|\n",
      "|  Aliquam Gravida PC|                 1|315021404|2021|August|Mon|  -452.9431699416258|Aliquam Gravida P...|\n",
      "|  Pede Nonummy Corp.|                 7|315031410|2021|  July|Fri| -123.63602658465202|Pede Nonummy Corp...|\n",
      "|       Vel Institute|                 1|305031120|2021|   May|Fri|  -77.77982384549502|Vel Institute3050...|\n",
      "|Sed Neque Associates|                 1|315031408|2021|  July|Fri|  -545.8554130974492|Sed Neque Associa...|\n",
      "|              Eu LLC|                 1|307031184|2021|  June|Wed|-0.20605760082653335|Eu LLC30703118420...|\n",
      "|   Felis Corporation|                 1|406021143|2021|   May|Fri|  -381.6842868762032|Felis Corporation...|\n",
      "|    Lacus Consulting|                 3|407021158|2021|  June|Fri|  -70.34227147032615|Lacus Consulting4...|\n",
      "|         Non Limited|                 1|209031215|2021|August|Sat|  -96.90235517574374|Non Limited209031...|\n",
      "|Praesent Eu Assoc...|                 1|511041290|2021|August|Thu|  -63.62928891386363|Praesent Eu Assoc...|\n",
      "|Tristique Pellent...|                 1|407031170|2021|August|Sat|  -167.5539791766433|Tristique Pellent...|\n",
      "|      Nam Associates|                 1|103011061|2021|August|Mon|  -46.81215258213584|Nam Associates103...|\n",
      "|Aliquam Gravida M...|                 1|401021006|2021|August|Fri| -111.59633859086017|Aliquam Gravida M...|\n",
      "|Lorem Ipsum Sodal...|                 1|801041034|2021|   May|Fri| -61.980571297246314|Lorem Ipsum Sodal...|\n",
      "|Dolor Egestas Rho...|                 1|406011130|2021|   May|Fri| -165.48742472286668|Dolor Egestas Rho...|\n",
      "|      Auctor Company|                 1|401031013|2021|   May|Thu| -126.14420836088647|Auctor Company401...|\n",
      "|Morbi Accumsan In...|                 1|301031017|2021|   May|Thu| -15.082859755950722|Morbi Accumsan In...|\n",
      "|Feugiat Sed Nec I...|                 1|205021085|2021|August|Thu| -48.199937637262934|Feugiat Sed Nec I...|\n",
      "|Tempus Scelerisqu...|                 1|301011003|2021|  June|Fri| -12.600630311477257|Tempus Scelerisqu...|\n",
      "+--------------------+------------------+---------+----+------+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a.createOrReplaceTempView(\"agg\")\n",
    "\n",
    "temp = spark.sql(\"\"\" \n",
    "\n",
    "SELECT merchant_name, COUNT(merchant_name) AS no_of_transactions, SA2_code, Year, Month, Day, SUM(take_rate - dollar_value) AS BNPL_earnings,\n",
    "    CONCAT(merchant_name, SA2_code, Year, Month, Day) AS join_col\n",
    "FROM agg\n",
    "GROUP BY merchant_name, SA2_code, Year, Month, Day\n",
    "\"\"\")\n",
    "\n",
    "temp.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_name</th><th>no_of_transactions</th><th>SA2_code</th><th>Year</th><th>Month</th><th>Day</th><th>BNPL_earnings</th><th>join_col</th><th>m_name</th><th>males</th><th>f_name</th><th>females</th></tr>\n",
       "<tr><td>A Arcu Industries</td><td>2</td><td>309011227</td><td>2021</td><td>October</td><td>Mon</td><td>-447.44732762052706</td><td>A Arcu Industries...</td><td>A Arcu Industries...</td><td>1</td><td>A Arcu Industries...</td><td>1</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>205031089</td><td>2022</td><td>August</td><td>Wed</td><td>-153.87443648170074</td><td>A Auctor Non Corp...</td><td>A Auctor Non Corp...</td><td>1</td><td>A Auctor Non Corp...</td><td>1</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>211051282</td><td>2022</td><td>October</td><td>Wed</td><td>-110.05960880156465</td><td>A Auctor Non Corp...</td><td>A Auctor Non Corp...</td><td>1</td><td>A Auctor Non Corp...</td><td>1</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>211051286</td><td>2021</td><td>September</td><td>Tue</td><td>-110.84792368624355</td><td>A Auctor Non Corp...</td><td>A Auctor Non Corp...</td><td>1</td><td>A Auctor Non Corp...</td><td>1</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>303041070</td><td>2022</td><td>May</td><td>Mon</td><td>-36.09463423218621</td><td>A Auctor Non Corp...</td><td>A Auctor Non Corp...</td><td>1</td><td>A Auctor Non Corp...</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+------------------+---------+----+---------+---+-------------------+--------------------+--------------------+-----+--------------------+-------+\n",
       "|       merchant_name|no_of_transactions| SA2_code|Year|    Month|Day|      BNPL_earnings|            join_col|              m_name|males|              f_name|females|\n",
       "+--------------------+------------------+---------+----+---------+---+-------------------+--------------------+--------------------+-----+--------------------+-------+\n",
       "|   A Arcu Industries|                 2|309011227|2021|  October|Mon|-447.44732762052706|A Arcu Industries...|A Arcu Industries...|    1|A Arcu Industries...|      1|\n",
       "|A Auctor Non Corp...|                 2|205031089|2022|   August|Wed|-153.87443648170074|A Auctor Non Corp...|A Auctor Non Corp...|    1|A Auctor Non Corp...|      1|\n",
       "|A Auctor Non Corp...|                 2|211051282|2022|  October|Wed|-110.05960880156465|A Auctor Non Corp...|A Auctor Non Corp...|    1|A Auctor Non Corp...|      1|\n",
       "|A Auctor Non Corp...|                 2|211051286|2021|September|Tue|-110.84792368624355|A Auctor Non Corp...|A Auctor Non Corp...|    1|A Auctor Non Corp...|      1|\n",
       "|A Auctor Non Corp...|                 2|303041070|2022|      May|Mon| -36.09463423218621|A Auctor Non Corp...|A Auctor Non Corp...|    1|A Auctor Non Corp...|      1|\n",
       "+--------------------+------------------+---------+----+---------+---+-------------------+--------------------+--------------------+-----+--------------------+-------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.createOrReplaceTempView(\"gender_join\")\n",
    "male.createOrReplaceTempView(\"m\")\n",
    "female.createOrReplaceTempView(\"f\")\n",
    "\n",
    "temp2 = spark.sql(\"\"\" \n",
    "\n",
    "SELECT *\n",
    "FROM gender_join\n",
    "INNER JOIN m\n",
    "ON gender_join.join_col = m.m_name\n",
    "\"\"\")\n",
    "\n",
    "temp2.createOrReplaceTempView(\"temp2\")\n",
    "\n",
    "temp3 = spark.sql(\"\"\" \n",
    "\n",
    "SELECT *\n",
    "FROM temp2\n",
    "INNER JOIN f\n",
    "ON temp2.join_col = f.f_name\n",
    "\"\"\")\n",
    "\n",
    "temp3.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SA2_code',\n",
       " 'total_males',\n",
       " 'total_females',\n",
       " 'income_2018-2019',\n",
       " 'total_persons')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'SA2_code', 'total_males', 'total_females','income_2018-2019','total_persons', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.withColumnRenamed('income_2018-2019',\n",
    "\n",
    "    'income_2018_2019'    \n",
    ")\n",
    "\n",
    "a = a.withColumn('income_per_persons',\n",
    "    (F.col('income_2018_2019')/F.col('total_persons'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 335:====================================>                   (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------+-----+------+-----------------+---------+---------+----------------+-----------+-------------+-------------+--------------------+----+------+---+------------------+\n",
      "|       merchant_name|take_rate|revenue_levels|state|gender|     dollar_value|postcodes| SA2_code|income_2018_2019|total_males|total_females|total_persons|            category|Year| Month|Day|income_per_persons|\n",
      "+--------------------+---------+--------------+-----+------+-----------------+---------+---------+----------------+-----------+-------------+-------------+--------------------+----+------+---+------------------+\n",
      "|Egestas Nunc Asso...|     6.58|             a|  NSW|  Male|11.28829564583802|     2299|111031231|       242936885|       6412|         6179|        12593|Books, Stationary...|2021|August|Fri|19291.422615738902|\n",
      "+--------------------+---------+--------------+-----+------+-----------------+---------+---------+----------------+-----------+-------------+-------------+--------------------+----+------+---+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 352:====================================>                   (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------+--------------------+------------+--------------+------------------+\n",
      "|      drop_name|take_rate|revenue_levels|            category|males_in_SA2|females_in_SA2| income_per_person|\n",
      "+---------------+---------+--------------+--------------------+------------+--------------+------------------+\n",
      "|   A Associates|     4.95|             b|Books, Stationary...|        9762|         10846|22526.523772559674|\n",
      "|A Felis Company|     4.32|             b|Books, Stationary...|        1080|          1051| 33927.61168708765|\n",
      "+---------------+---------+--------------+--------------------+------------+--------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a.createOrReplaceTempView(\"features\")\n",
    "\n",
    "e = spark.sql(\"\"\" \n",
    "\n",
    "SELECT merchant_name AS drop_name, FIRST(take_rate) AS take_rate, FIRST(revenue_levels) AS revenue_levels, FIRST(category) AS category,\n",
    "    FIRST(total_males) AS males_in_SA2, FIRST(total_females) AS females_in_SA2, FIRST(income_per_persons) AS income_per_person\n",
    "FROM features\n",
    "GROUP BY merchant_name\n",
    "\"\"\")\n",
    "\n",
    "e.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 379:> (0 + 8) / 14][Stage 380:> (0 + 0) / 14][Stage 381:> (0 + 0) / 14]  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:56:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_name</th><th>no_of_transactions</th><th>SA2_code</th><th>Year</th><th>Month</th><th>Day</th><th>BNPL_earnings</th><th>males</th><th>females</th><th>take_rate</th><th>revenue_levels</th><th>category</th><th>males_in_SA2</th><th>females_in_SA2</th><th>income_per_person</th></tr>\n",
       "<tr><td>A Arcu Industries</td><td>2</td><td>309011227</td><td>2021</td><td>October</td><td>Mon</td><td>-447.44732762052706</td><td>1</td><td>1</td><td>3.0</td><td>c</td><td>Furniture</td><td>4821</td><td>4683</td><td>25816.03452631579</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>205031089</td><td>2022</td><td>August</td><td>Wed</td><td>-153.87443648170074</td><td>1</td><td>1</td><td>5.58</td><td>a</td><td>Furniture</td><td>2067</td><td>2014</td><td>22634.72370679088</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>211051282</td><td>2022</td><td>October</td><td>Wed</td><td>-110.05960880156465</td><td>1</td><td>1</td><td>5.58</td><td>a</td><td>Furniture</td><td>2067</td><td>2014</td><td>22634.72370679088</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>211051286</td><td>2021</td><td>September</td><td>Tue</td><td>-110.84792368624355</td><td>1</td><td>1</td><td>5.58</td><td>a</td><td>Furniture</td><td>2067</td><td>2014</td><td>22634.72370679088</td></tr>\n",
       "<tr><td>A Auctor Non Corp...</td><td>2</td><td>303041070</td><td>2022</td><td>May</td><td>Mon</td><td>-36.09463423218621</td><td>1</td><td>1</td><td>5.58</td><td>a</td><td>Furniture</td><td>2067</td><td>2014</td><td>22634.72370679088</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+------------------+---------+----+---------+---+-------------------+-----+-------+---------+--------------+---------+------------+--------------+-----------------+\n",
       "|       merchant_name|no_of_transactions| SA2_code|Year|    Month|Day|      BNPL_earnings|males|females|take_rate|revenue_levels| category|males_in_SA2|females_in_SA2|income_per_person|\n",
       "+--------------------+------------------+---------+----+---------+---+-------------------+-----+-------+---------+--------------+---------+------------+--------------+-----------------+\n",
       "|   A Arcu Industries|                 2|309011227|2021|  October|Mon|-447.44732762052706|    1|      1|      3.0|             c|Furniture|        4821|          4683|25816.03452631579|\n",
       "|A Auctor Non Corp...|                 2|205031089|2022|   August|Wed|-153.87443648170074|    1|      1|     5.58|             a|Furniture|        2067|          2014|22634.72370679088|\n",
       "|A Auctor Non Corp...|                 2|211051282|2022|  October|Wed|-110.05960880156465|    1|      1|     5.58|             a|Furniture|        2067|          2014|22634.72370679088|\n",
       "|A Auctor Non Corp...|                 2|211051286|2021|September|Tue|-110.84792368624355|    1|      1|     5.58|             a|Furniture|        2067|          2014|22634.72370679088|\n",
       "|A Auctor Non Corp...|                 2|303041070|2022|      May|Mon| -36.09463423218621|    1|      1|     5.58|             a|Furniture|        2067|          2014|22634.72370679088|\n",
       "+--------------------+------------------+---------+----+---------+---+-------------------+-----+-------+---------+--------------+---------+------------+--------------+-----------------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3.createOrReplaceTempView(\"edit\")\n",
    "e.createOrReplaceTempView(\"rates\")\n",
    "\n",
    "temp4 = spark.sql(\"\"\" \n",
    "\n",
    "SELECT *\n",
    "FROM edit\n",
    "INNER JOIN rates\n",
    "ON edit.merchant_name = rates.drop_name\n",
    "\"\"\")\n",
    "\n",
    "train = temp4.drop('m_name', 'f_name', 'drop_name','join_col')\n",
    "\n",
    "train.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- no_of_transactions: long (nullable = false)\n",
      " |-- SA2_code: long (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- BNPL_earnings: double (nullable = true)\n",
      " |-- males: long (nullable = false)\n",
      " |-- females: long (nullable = false)\n",
      " |-- take_rate: double (nullable = true)\n",
      " |-- revenue_levels: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- males_in_SA2: long (nullable = true)\n",
      " |-- females_in_SA2: long (nullable = true)\n",
      " |-- income_per_person: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "507978"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# String indexing the categorical columns\n",
    "\n",
    "indexer = StringIndexer(inputCols = ['merchant_name', 'SA2_code', 'Year', 'Month', 'Day', 'revenue_levels','category'],\n",
    "outputCols = ['merchant_name_num', 'SA2_code_num', 'Year_num', 'Month_num', 'Day_num', 'revenue_levels_num','category_num'])\n",
    "\n",
    "indexd_data = indexer.fit(train).transform(train)\n",
    "\n",
    "\n",
    "# Applying onehot encoding to the categorical data that is string indexed above\n",
    "encoder = OneHotEncoder(inputCols = ['merchant_name_num', 'SA2_code_num', 'Year_num', 'Month_num', 'Day_num', 'revenue_levels_num','category_num'],\n",
    "outputCols = ['merchant_name_vec', 'SA2_code_vec', 'Year_vec', 'Month_vec', 'Day_vec', 'revenue_levels_vec','category_vec'])\n",
    "\n",
    "onehotdata = encoder.fit(indexd_data).transform(indexd_data)\n",
    "\n",
    "\n",
    "# Assembling the training data as a vector of features \n",
    "assembler1 = VectorAssembler(\n",
    "inputCols=['no_of_transactions','take_rate', 'merchant_name_vec', 'SA2_code_vec', 'Year_vec', 'Month_vec', 'Day_vec', 'revenue_levels_vec','category_vec','males_in_SA2', 'females_in_SA2', 'income_per_person'],\n",
    "outputCol= \"features\" )\n",
    "\n",
    "outdata1 = assembler1.transform(onehotdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the target column as label\n",
    "\n",
    "outdata1 = outdata1.withColumnRenamed(\n",
    "    \"BNPL_earnings\",\n",
    "    \"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 607:> (0 + 8) / 14][Stage 608:> (0 + 0) / 14][Stage 609:> (0 + 0) / 14]4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:58:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Assembling the features as a feature vector \n",
    "\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", \n",
    "    outputCol=\"indexedFeatures\").fit(outdata1)\n",
    "\n",
    "outdata1 = featureIndexer.transform(outdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "\n",
    "trainingData, testData = outdata1.randomSplit([0.7, 0.3], seed = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 651:> (0 + 8) / 14][Stage 652:> (0 + 0) / 14][Stage 653:> (0 + 0) / 14]  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 651:=>(8 + 6) / 14][Stage 652:> (0 + 2) / 14][Stage 653:> (0 + 0) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:59:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/04 21:59:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 668:======================================>                  (6 + 3) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 21:59:58 WARN DAGScheduler: Broadcasting large task binary with size 1309.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 732:=========================>                               (4 + 5) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:00:41 WARN DAGScheduler: Broadcasting large task binary with size 1309.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(355294, 152684)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.count(), testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 796:===================>                                     (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:21 WARN DAGScheduler: Broadcasting large task binary with size 1316.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:23 WARN DAGScheduler: Broadcasting large task binary with size 1316.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:31 WARN DAGScheduler: Broadcasting large task binary with size 1320.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:38 WARN DAGScheduler: Broadcasting large task binary with size 1472.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 841:>                                                       (0 + 8) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_3 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_7 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_6 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_2 in memory! (computed 112.5 MiB so far)\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_5 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_4 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_3 to disk instead.\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_4 to disk instead.\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_2 to disk instead.\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_5 to disk instead.\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_6 to disk instead.\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_7 to disk instead.\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_1 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_1 to disk instead.\n",
      "22/10/04 22:01:44 WARN MemoryStore: Not enough space to cache rdd_1915_0 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:44 WARN BlockManager: Persisting block rdd_1915_0 to disk instead.\n",
      "22/10/04 22:01:46 WARN MemoryStore: Not enough space to cache rdd_1915_0 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:46 WARN MemoryStore: Not enough space to cache rdd_1915_1 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:46 WARN MemoryStore: Not enough space to cache rdd_1915_6 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:46 WARN MemoryStore: Not enough space to cache rdd_1915_2 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:46 WARN MemoryStore: Not enough space to cache rdd_1915_4 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:46 WARN MemoryStore: Not enough space to cache rdd_1915_5 in memory! (computed 255.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 841:====================================>                   (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:53 WARN MemoryStore: Not enough space to cache rdd_1915_9 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:53 WARN BlockManager: Persisting block rdd_1915_9 to disk instead.\n",
      "22/10/04 22:01:53 WARN MemoryStore: Not enough space to cache rdd_1915_11 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:53 WARN BlockManager: Persisting block rdd_1915_11 to disk instead.\n",
      "22/10/04 22:01:53 WARN MemoryStore: Not enough space to cache rdd_1915_8 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:53 WARN BlockManager: Persisting block rdd_1915_8 to disk instead.\n",
      "22/10/04 22:01:53 WARN MemoryStore: Not enough space to cache rdd_1915_12 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:53 WARN BlockManager: Persisting block rdd_1915_12 to disk instead.\n",
      "22/10/04 22:01:53 WARN MemoryStore: Not enough space to cache rdd_1915_10 in memory! (computed 255.3 MiB so far)\n",
      "22/10/04 22:01:53 WARN BlockManager: Persisting block rdd_1915_10 to disk instead.\n",
      "22/10/04 22:01:54 WARN MemoryStore: Not enough space to cache rdd_1915_12 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:54 WARN MemoryStore: Not enough space to cache rdd_1915_11 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:01:54 WARN MemoryStore: Not enough space to cache rdd_1915_9 in memory! (computed 255.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:56 WARN DAGScheduler: Broadcasting large task binary with size 1550.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 853:>                                                       (0 + 8) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:01:57 WARN MemoryStore: Not enough space to cache rdd_1915_1 in memory! (computed 112.5 MiB so far)\n",
      "22/10/04 22:01:57 WARN MemoryStore: Not enough space to cache rdd_1915_0 in memory! (computed 112.5 MiB so far)\n",
      "22/10/04 22:01:57 WARN MemoryStore: Not enough space to cache rdd_1915_4 in memory! (computed 112.5 MiB so far)\n",
      "22/10/04 22:01:57 WARN MemoryStore: Not enough space to cache rdd_1915_5 in memory! (computed 112.5 MiB so far)\n",
      "22/10/04 22:01:57 WARN MemoryStore: Not enough space to cache rdd_1915_2 in memory! (computed 112.5 MiB so far)\n",
      "22/10/04 22:01:57 WARN MemoryStore: Not enough space to cache rdd_1915_6 in memory! (computed 168.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 853:================================>                       (8 + 6) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:02 WARN MemoryStore: Not enough space to cache rdd_1915_12 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:02:02 WARN MemoryStore: Not enough space to cache rdd_1915_11 in memory! (computed 255.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:05 WARN DAGScheduler: Broadcasting large task binary with size 1695.8 KiB\n",
      "22/10/04 22:02:05 WARN MemoryStore: Not enough space to cache rdd_1915_6 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:05 WARN MemoryStore: Not enough space to cache rdd_1915_1 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:05 WARN MemoryStore: Not enough space to cache rdd_1915_2 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:05 WARN MemoryStore: Not enough space to cache rdd_1915_5 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:05 WARN MemoryStore: Not enough space to cache rdd_1915_0 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:05 WARN MemoryStore: Not enough space to cache rdd_1915_4 in memory! (computed 74.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 865:================================>                       (8 + 6) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:10 WARN MemoryStore: Not enough space to cache rdd_1915_12 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:02:10 WARN MemoryStore: Not enough space to cache rdd_1915_11 in memory! (computed 255.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:13 WARN DAGScheduler: Broadcasting large task binary with size 1921.5 KiB\n",
      "22/10/04 22:02:13 WARN MemoryStore: Not enough space to cache rdd_1915_5 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:13 WARN MemoryStore: Not enough space to cache rdd_1915_2 in memory! (computed 49.0 MiB so far)\n",
      "22/10/04 22:02:13 WARN MemoryStore: Not enough space to cache rdd_1915_1 in memory! (computed 49.0 MiB so far)\n",
      "22/10/04 22:02:14 WARN MemoryStore: Not enough space to cache rdd_1915_4 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:14 WARN MemoryStore: Not enough space to cache rdd_1915_0 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:14 WARN MemoryStore: Not enough space to cache rdd_1915_6 in memory! (computed 112.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 877:================================>                       (8 + 6) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:18 WARN MemoryStore: Not enough space to cache rdd_1915_11 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:02:19 WARN MemoryStore: Not enough space to cache rdd_1915_12 in memory! (computed 255.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:22 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/10/04 22:02:22 WARN MemoryStore: Not enough space to cache rdd_1915_6 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:22 WARN MemoryStore: Not enough space to cache rdd_1915_5 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:22 WARN MemoryStore: Not enough space to cache rdd_1915_4 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:22 WARN MemoryStore: Not enough space to cache rdd_1915_1 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:22 WARN MemoryStore: Not enough space to cache rdd_1915_2 in memory! (computed 74.8 MiB so far)\n",
      "22/10/04 22:02:22 WARN MemoryStore: Not enough space to cache rdd_1915_0 in memory! (computed 74.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 889:================================>                       (8 + 6) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:02:27 WARN MemoryStore: Not enough space to cache rdd_1915_12 in memory! (computed 168.8 MiB so far)\n",
      "22/10/04 22:02:27 WARN MemoryStore: Not enough space to cache rdd_1915_11 in memory! (computed 255.3 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "\n",
    "# Train model.  \n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_validation = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 933:>                                                        (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:03:05 WARN DAGScheduler: Broadcasting large task binary with size 1324.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|         prediction|              label|            features|\n",
      "+-------------------+-------------------+--------------------+\n",
      "|-238.70533997597204|-110.05960880156465|(2835,[0,1,222,17...|\n",
      "|-238.70533997597204| -27.13087366041648|(2835,[0,1,222,17...|\n",
      "|-238.70533997597204| -257.3289665843789|(2835,[0,1,222,17...|\n",
      "|-238.70533997597204|-122.97252883408981|(2835,[0,1,222,17...|\n",
      "|-201.78667914470756|-417.99304299678636|(2835,[0,1,490,21...|\n",
      "+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 985:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:03:41 WARN DAGScheduler: Broadcasting large task binary with size 1321.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:03:48 WARN DAGScheduler: Broadcasting large task binary with size 1322.8 KiB\n",
      "Root Mean Squared Error (RMSE) on train data = 221.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1038:==================>                                     (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:04:23 WARN DAGScheduler: Broadcasting large task binary with size 1321.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1049:===================================>                   (9 + 5) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 22:04:30 WARN DAGScheduler: Broadcasting large task binary with size 1322.8 KiB\n",
      "Root Mean Squared Error (MAE) on train data = 119.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the validation set \n",
    "\n",
    "predictions_validation.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "\n",
    "evaluator_train_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse_train = evaluator_train_rmse.evaluate(predictions_validation)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse_train)\n",
    "\n",
    "evaluator_train_mae = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae_train = evaluator_train_mae.evaluate(predictions_validation)\n",
    "print(\"Root Mean Squared Error (MAE) on train data = %g\" % mae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afcda84b7471a9b9fde108a34f159f021985318d3feb99cad4970c959fa9ac9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
